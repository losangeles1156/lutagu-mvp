import { NextRequest, NextResponse } from 'next/server';
import { RecommendRequest, MatchedStrategyCard, EvaluationContext } from '@/types/lutagu_l4';
import { decisionEngine } from '@/lib/l4/decisionEngine';
import { hardCalculationEngine } from '@/lib/l4/hardCalculationEngine';
import { generateLLMResponse } from '@/lib/ai/llmClient';

export async function POST(req: NextRequest) {
    try {
        const body: RecommendRequest = await req.json();
        const { stationId, lineIds, userPreferences, locale } = body;

        const context: EvaluationContext = {
            stationId,
            lineIds: lineIds || [],
            userPreferences,
            currentDate: new Date(),
            locale
        };

        console.log('[L4 API] Evaluating for:', context.stationId);

        // 1. Soft Calculation (Rule-based / SLM)
        const softCards = decisionEngine.evaluate(context);

        // 2. Hard Calculation (Real-time / ODPT)
        let hardCards: MatchedStrategyCard[] = [];
        try {
            hardCards = await hardCalculationEngine.evaluate(context);
        } catch (e) {
            console.error('[L4 API] Hard calculation failed:', e);
        }

        // 3. Merge & Sort
        let cards = [...hardCards, ...softCards].sort((a, b) => b.priority - a.priority);

        // 4. LLM Fallback (If no high-value cards found)
        // We only trigger LLM if we have 0 cards, or only low-priority info cards.
        // This strictly follows the "10% LLM" rule - only when necessary.
        const hasHighValue = cards.some(c => c.priority >= 50);

        if (!hasHighValue) {
            try {
                const systemPrompt = locale === 'zh-TW'
                    ? 'ä½ æ˜¯æ±äº¬äº¤é€šåŠ©æ‰‹ BambiGOã€‚ç”¨æˆ¶ç›®å‰åœ¨è»Šç«™é‡åˆ°å›°é›£ï¼Œä¸”æˆ‘å€‘çš„è¦å‰‡åº«æ²’æœ‰åŒ¹é…åˆ°ç‰¹å®šå»ºè­°ã€‚è«‹æ ¹æ“šç”¨æˆ¶æƒ…å¢ƒï¼ˆè¡ŒæŽã€å¤©æ°£ã€åŒè¡Œè€…ï¼‰æä¾›ä¸€å€‹ç°¡çŸ­ã€æº«æš–ä¸”å¯¦ç”¨çš„é€šç”¨å»ºè­° (50å­—ä»¥å…§)ã€‚'
                    : 'You are BambiGO, a Tokyo transit assistant. The user is at a station and our rule engine found no matches. Provide short, warm, practical general advice based on their context (max 30 words).';

                const userPrompt = `Station: ${stationId}\nPreferences: ${JSON.stringify(userPreferences)}\nContext: No specific rules matched.`;

                const aiText = await generateLLMResponse({ systemPrompt, userPrompt });

                if (aiText) {
                    cards.push({
                        id: 'ai-fallback-advice',
                        type: 'ai_suggestion',
                        priority: 45, // Lower than rules, higher than empty
                        icon: 'ðŸ¤–',
                        title: locale === 'zh-TW' ? 'Bambi åŠ©æ‰‹å»ºè­°' : 'AI Suggestion',
                        description: aiText,
                        _debug_reason: 'Generated by Mistral (10% Layer)'
                    });
                }
            } catch (e) {
                console.error('[L4 API] LLM generation failed:', e);
            }
        }

        // 5. Final Fallback (Static)
        if (cards.length === 0) {
            cards.push({
                id: 'fallback-default',
                type: 'info',
                icon: 'ðŸ§­',
                title: locale === 'zh-TW' ? 'è‡ªç”±æŽ¢ç´¢' : 'Explore',
                description: locale === 'zh-TW'
                    ? 'ç›®å‰æ²’æœ‰é‡å°æ­¤å ´æ™¯çš„ç‰¹åˆ¥å»ºè­°ï¼Œè«‹æŽ¢ç´¢å‘¨é‚Šæˆ–è¼¸å…¥å…·é«”ç›®çš„åœ°ã€‚'
                    : 'No specific advice for this context. Please explore nearby.',
                priority: 0,
                _debug_reason: undefined
            });
        }

        return NextResponse.json({
            cards: cards.map(c => ({
                ...c,
            }))
        });

    } catch (error) {
        console.error('[L4 API] Error:', error);
        return NextResponse.json({ error: 'Internal Server Error' }, { status: 500 });
    }
}
