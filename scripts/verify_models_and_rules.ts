
import { generateLLMResponse } from '../src/lib/ai/llmClient';
import { hybridEngine } from '../src/lib/l4/HybridEngine';
import * as dotenv from 'dotenv';
import path from 'path';
dotenv.config({ path: path.resolve(process.cwd(), '.env.local') });

async function testModelConnectivity() {
    console.log('--- ğŸ§ª Testing Model Connectivity ---');

    // 1. Test Gemini 3 Flash Preview (via synthesis)
    console.log('\n[1/3] Testing Gemini 3 Flash Preview (Task: synthesis)');
    const gen3 = await generateLLMResponse({
        systemPrompt: "You are a helpful assistant. Reply in Traditional Chinese.",
        userPrompt: "Hello, who are you? Please mention your model name if you know it.",
        taskType: 'synthesis'
    });
    console.log('Response:', gen3);

    // 2. Test Gemini 2.5 Flash Lite (via classification)
    console.log('\n[2/3] Testing Gemini 2.5 Flash Lite (Task: classification)');
    const gen25 = await generateLLMResponse({
        systemPrompt: "You are a text classifier. Reply with one word.",
        userPrompt: "Is this a traffic query: 'How to go to Ueno?'",
        taskType: 'classification'
    });
    console.log('Response:', gen25);

    // 3. Test MiniMax-M2.1 (via reasoning)
    console.log('\n[3/3] Testing MiniMax-M2.1 (Task: reasoning)');
    const minimax = await generateLLMResponse({
        systemPrompt: "You are a reasoning expert. Reply in Traditional Chinese.",
        userPrompt: "åˆ†æä¸€ä¸‹ç‚ºä»€éº¼ä¸Šé‡ç«™æœ‰é€™éº¼å¤šæ¢ç·šè·¯æ•´åˆï¼Ÿ",
        taskType: 'reasoning'
    });
    console.log('Response:', minimax);
}

async function testHybridRules() {
    console.log('\n--- ğŸ§  Testing Architecture Rules (Persona & Formatting) ---');

    const queries = [
        "ä¸Šé‡ç«™æ€éº¼å»æ·ºè‰ï¼Ÿ",
        "æ–°å®¿è»Šç«™äººå¤šå—ï¼Ÿ",
        "æ¨è–¦ä¸€ä¸‹æ¾€è°·å¥½åƒçš„æ‹‰éºµ"
    ];

    for (const text of queries) {
        console.log(`\nQuery: "${text}"`);
        const response = await hybridEngine.processRequest({
            text,
            locale: 'zh-TW',
            context: {
                currentStation: 'Tokyo',
                userLocation: { lat: 35.6812, lng: 139.7671 }
            }
        });

        if (response) {
            console.log('Source:', response.source);
            console.log('Type:', response.type);
            console.log('Content:', response.content);

            // Validation
            const hasBold = response.content.includes('**');
            const hasHeading = response.content.includes('#');
            const hasList = /^\d\.|\n- /m.test(response.content);
            const sentenceCount = response.content.split(/[ã€‚ï¼ï¼Ÿ\n]/).filter(s => s.trim().length > 0).length;

            console.log('Validation:');
            console.log(`- No Bold: ${!hasBold ? 'âœ…' : 'âŒ'}`);
            console.log(`- No Headings: ${!hasHeading ? 'âœ…' : 'âŒ'}`);
            console.log(`- No Lists: ${!hasList ? 'âœ…' : 'âŒ'}`);
            console.log(`- Concise (${sentenceCount} sentences): ${sentenceCount <= 3 ? 'âœ…' : 'âš ï¸ (Max 3 sentences)'}`);
        } else {
            console.log('âŒ No response from engine');
        }
    }
}

async function runAll() {
    try {
        await testModelConnectivity();
        await testHybridRules();
    } catch (e) {
        console.error('Test failed:', e);
    }
}

runAll();
