
import dotenv from 'dotenv';
dotenv.config({ path: '.env.local' });
import { generateLLMResponse } from '../src/lib/ai/llmClient';

async function verifyMiniMax() {
    console.log("üîç Checking MiniMax Connection...");

    // Log masked key to verify it's loaded
    const key = process.env.MINIMAX_API_KEY;
    if (!key) {
        console.error("‚ùå MINIMAX_API_KEY is missing in process.env");
        return;
    }
    console.log("‚úÖ MINIMAX_API_KEY found (length: " + key.length + ")");

    const startTime = Date.now();
    const response = await generateLLMResponse({
        systemPrompt: "You are a helpful assistant.",
        userPrompt: "Is this the MiniMax model? Answer 'Yes, I am MiniMax' if you are.",
        taskType: 'reasoning',
        temperature: 0.1
    });
    const duration = Date.now() - startTime;

    console.log("\n--------------------------------");
    console.log(`‚è±Ô∏è Duration: ${duration}ms`);
    console.log(`üìù Response: ${response}`);

    if (response) {
        console.log("‚úÖ API Call Successful");
        // Additional info in case it fell back
        if (typeof response === 'string' && response.includes('MiniMax')) {
            console.log("‚úÖ Confirmed MiniMax Identity");
        }
    } else {
        console.log("‚ùå API Call Failed (Returned null)");
    }
}

verifyMiniMax();
