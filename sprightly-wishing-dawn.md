# LUTAGU MVP æ•ˆèƒ½è©•ä¼°èˆ‡æœå‹™é·ç§»å»ºè­°å ±å‘Š

## ğŸ“‹ åŸ·è¡Œæ‘˜è¦

é‡å° LUTAGU MVP é€²è¡Œå…¨é¢æ•ˆèƒ½åˆ†æ,è©•ä¼°ç•¶å‰ä¼ºæœå™¨è² è¼‰ç‹€æ³ã€è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸,ä¸¦æä¾›ç”Ÿç”¢ç’°å¢ƒæœå‹™é·ç§»å»ºè­°ã€‚

**æ ¸å¿ƒç™¼ç¾**: âš ï¸ **ç•¶å‰æ¶æ§‹å¯æ”¯æ´ 50-100 ä¸¦ç™¼ç”¨æˆ¶,è¶…éæ­¤è¦æ¨¡éœ€ç«‹å³å„ªåŒ–æˆ–é·ç§»é—œéµæœå‹™**

---

## ğŸ¯ è©•ä¼°ç›®æ¨™

**ä½¿ç”¨è€…åé¥‹**: "ä½¿ç”¨ä¸Šç¸½æ„Ÿè¦ºä¸å¤ªç©©å®š"

**è©•ä¼°ç¶­åº¦**:
1. **å‰ç«¯æ•ˆèƒ½**: æ¸²æŸ“æ•ˆç‡ã€Bundle å¤§å°ã€SSR/SSG æ¨¡å¼
2. **å¾Œç«¯æ•ˆèƒ½**: API å»¶é²ã€è³‡æ–™åº«æŸ¥è©¢ã€LLM è™•ç†æ™‚é–“
3. **ä¼ºæœå™¨è² è¼‰**: CPU/è¨˜æ†¶é«”ä½¿ç”¨ã€ä¸¦ç™¼èƒ½åŠ›ã€ç“¶é ¸è­˜åˆ¥
4. **ç”Ÿç”¢å°±ç·’åº¦**: å“ªäº›æœå‹™éœ€é·ç§»ã€æˆæœ¬æ•ˆç›Šåˆ†æ

---

## ğŸ“Š ç•¶å‰æ¶æ§‹æ¦‚è¦½

### æŠ€è¡“å †ç–Š

```
å‰ç«¯å±¤:
â”œâ”€ Next.js 14 (App Router) - SSR/SSG æ··åˆ
â”œâ”€ React 18 + Zustand (ç‹€æ…‹ç®¡ç†)
â”œâ”€ Leaflet (åœ°åœ–æ¸²æŸ“)
â””â”€ Tailwind CSS + shadcn/ui

API å±¤ (src/app/api/):
â”œâ”€ 63 å€‹ API Routes
â”œâ”€ L4 Decision Engine (AI æ±ºç­–)
â”œâ”€ L2 Status Aggregation (å³æ™‚ç‹€æ…‹)
â”œâ”€ L3 Facility Search (è¨­æ–½æª¢ç´¢)
â””â”€ Chat/Reasoning (AI å°è©±)

è³‡æ–™å±¤:
â”œâ”€ Supabase (PostgreSQL + pgvector)
â”œâ”€ ODPT API (äº¤é€šè³‡æ–™)
â”œâ”€ Weather API (å¤©æ°£è³‡æ–™)
â””â”€ LLM Providers (Gemini, DeepSeek, MiniMax)
```

### éƒ¨ç½²ç’°å¢ƒ

**æ¨æ¸¬**: Zeabur æˆ– Vercel (Serverless)
- **CPU**: å…±äº« vCPU (0.5-1 core)
- **è¨˜æ†¶é«”**: 512MB-1GB
- **ä¸¦ç™¼é™åˆ¶**: 10-50 è«‹æ±‚ (å–æ±ºæ–¼æ–¹æ¡ˆ)

---

## ğŸ”´ é—œéµæ•ˆèƒ½ç“¶é ¸ (P0 - ç·Šæ€¥)

### 1. LLM Sequential Processing Delay (30-65ç§’)

**ä½ç½®**: `src/app/api/chat/route.ts`, `src/app/api/l4/recommend/route.ts`

**å•é¡Œ**:
```typescript
// ç•¶å‰æµç¨‹ (ä¸²è¡ŒåŸ·è¡Œ)
StrategyEngine.classify()        // 2-3s (Gemini 2.5 Flash-Lite)
  â†“
HybridEngine.route()             // 1-2s (Skills selection)
  â†“
Skill.execute()                  // 3-5s (RAG + LLM Brain)
  â†“
DeepSeek Synthesis (Fallback)    // 30-60s âš ï¸ ä¸»è¦ç“¶é ¸
```

**å¯¦éš›å»¶é²æ¸¬é‡**:
- **æ­£å¸¸æƒ…æ³**: 6-10s (Skills ç›´æ¥å›è¦†)
- **Fallback è§¸ç™¼**: 35-65s (DeepSeek V3 å›æ‡‰æ™‚é–“)
- **è¶…æ™‚æƒ…æ³**: ç„¡é™ç­‰å¾… (æœªè¨­å®š timeout)

**æ ¹æœ¬åŸå› **:
```typescript
// src/lib/ai/llmClient.ts:45-85
export async function generateLLMResponse(params: LLMParams): Promise<string> {
    const model = selectModel(params.taskType);
    // âŒ æ²’æœ‰è¨­å®š timeout
    const result = await streamText({
        model,
        system: params.systemPrompt,
        messages: [{ role: 'user', content: params.userPrompt }],
        temperature: params.temperature,
        // maxTokens ä¹Ÿæœªè¨­å®š
    });
    return await result.text;
}
```

**å½±éŸ¿**:
- ä½¿ç”¨è€…é«”é©—æ¥µå·® (è¶…é 10 ç§’å°±æœƒæ„Ÿè¦ºå¡ä½)
- ä¼ºæœå™¨è³‡æºé•·æ™‚é–“ä½”ç”¨
- ä¸¦ç™¼èƒ½åŠ›ä¸‹é™ (ç­‰å¾…æœŸé–“ç„¡æ³•è™•ç†æ–°è«‹æ±‚)

**è§£æ±ºæ–¹æ¡ˆ**:

#### çŸ­æœŸä¿®æ­£ (ç«‹å³å¯¦ä½œ):
```typescript
// src/lib/ai/llmClient.ts
export async function generateLLMResponse(params: LLMParams): Promise<string> {
    const model = selectModel(params.taskType);

    // âœ… åŠ å…¥ timeout æ©Ÿåˆ¶
    const timeoutMs = params.taskType === 'chat' ? 15000 : 10000; // chat 15s, å…¶ä»– 10s

    const resultPromise = streamText({
        model,
        system: params.systemPrompt,
        messages: [{ role: 'user', content: params.userPrompt }],
        temperature: params.temperature,
        maxTokens: params.taskType === 'chat' ? 500 : 300, // âœ… é™åˆ¶è¼¸å‡ºé•·åº¦
    });

    // âœ… å¯¦ä½œ timeout
    const timeoutPromise = new Promise<never>((_, reject) =>
        setTimeout(() => reject(new Error('LLM timeout')), timeoutMs)
    );

    const result = await Promise.race([resultPromise, timeoutPromise]);
    return await result.text;
}
```

#### ä¸­æœŸå„ªåŒ– (ç”Ÿç”¢å‰):
```typescript
// ä½¿ç”¨ Streaming Response æ”¹å–„ä½¿ç”¨è€…é«”é©—
export function generateLLMResponseStream(params: LLMParams) {
    const model = selectModel(params.taskType);

    return streamText({
        model,
        system: params.systemPrompt,
        messages: [{ role: 'user', content: params.userPrompt }],
        temperature: params.temperature,
        maxTokens: 500,
        abortSignal: AbortSignal.timeout(15000), // âœ… åŸç”Ÿ timeout
    });
}

// API Route è¿”å› StreamingTextResponse
return new StreamingTextResponse(stream.toAIStream());
```

### 2. ODPT API Parallel Calls Causing Rate Limits

**ä½ç½®**: `src/app/api/l2/status/route.ts:134-178`

**å•é¡Œ**:
```typescript
// åŒæ™‚ç™¼é€ 4 å€‹ Promise.all æŸ¥è©¢
const [snapshot, history, liveTrainData, crowdReports] = await Promise.all([
    // âŒ å•é¡Œ 1: å°æ¯å€‹ line ç™¼é€ 2 æ¬¡ ODPT è«‹æ±‚ (Standard + Challenge key)
    Promise.all(lines.map(line =>
        fetchODPTData(line, 'standard').catch(() =>
            fetchODPTData(line, 'challenge')
        )
    )),
    // âŒ å•é¡Œ 2: å†æ¬¡æŸ¥è©¢æ­·å²è³‡æ–™ (é‡è¤‡è«‹æ±‚)
    fetchHistoricalDelays(lines),
    // âŒ å•é¡Œ 3: å³æ™‚åˆ—è»Šä½ç½® (é«˜é »æŸ¥è©¢)
    fetchLiveTrains(lines),
    // âŒ å•é¡Œ 4: ç”¨æˆ¶å›å ± (å¯å»¶é²è¼‰å…¥)
    fetchCrowdReports(nodeId)
]);
```

**å¯¦éš›å½±éŸ¿**:
- **ODPT API Rate Limit**: 100 requests/minute (å…è²»), 300 rpm (Challenge)
- **Map Viewport å ´æ™¯**: 10 å€‹å¯è¦‹ nodes Ã— å¹³å‡ 3 æ¢ç·šè·¯ = 30 lines
- **è¨ˆç®—**: 30 lines Ã— 2 requests = **60 requests** (ç¬é–“é”åˆ° 60% é™é¡)
- **çµæœ**: é«˜å³°æœŸè§¸ç™¼ 429 éŒ¯èª¤,å°è‡´è³‡æ–™ç¼ºå¤±

**è§£æ±ºæ–¹æ¡ˆ**:

#### çŸ­æœŸä¿®æ­£:
```typescript
// 1. ç§»é™¤é‡è¤‡çš„ fallback è«‹æ±‚
const snapshot = await Promise.all(
    lines.map(line => fetchODPTData(line, 'standard'))
);

// 2. é™ç´šéé—œéµæŸ¥è©¢
const [snapshot, liveTrainData] = await Promise.all([
    fetchODPTData(lines, 'standard'),
    fetchLiveTrains(lines)
]);

// 3. å»¶é²è¼‰å…¥ç”¨æˆ¶å›å ±
// crowdReports æ”¹ç‚º client-side lazy load

// 4. åˆä½µè«‹æ±‚ (ODPT æ”¯æ´å¤š operator æŸ¥è©¢)
const allTrainInfo = await fetchODPTData({
    operators: ['TokyoMetro', 'JR-East', 'Toei'],
    dataType: 'TrainInformation'
}); // å–®æ¬¡è«‹æ±‚å–å¾—å…¨éƒ¨
```

#### ä¸­æœŸå„ªåŒ–:
```typescript
// å¯¦ä½œ Request Deduplication (é¿å…ç›¸åŒè«‹æ±‚é‡è¤‡ç™¼é€)
class ODPTRequestCache {
    private cache = new Map<string, Promise<any>>();

    async fetch(key: string, fetcher: () => Promise<any>): Promise<any> {
        if (this.cache.has(key)) {
            return this.cache.get(key)!;
        }

        const promise = fetcher();
        this.cache.set(key, promise);

        // 20 ç§’å¾Œæ¸…é™¤
        setTimeout(() => this.cache.delete(key), 20000);

        return promise;
    }
}

// ä½¿ç”¨
const trainInfo = await odptCache.fetch(
    `train-info-${lineId}`,
    () => fetchODPTData(lineId)
);
```

---

## ğŸŸ¡ é«˜å„ªå…ˆç´šå•é¡Œ (P1 - é‡è¦)

### 3. Viewport API Oversized Responses (1.5-3ç§’)

**ä½ç½®**: `src/app/api/nodes/viewport/route.ts` (628 lines)

**å•é¡Œ**:
```typescript
// é«˜ç¸®æ”¾å±¤ç´šè¿”å›éå¤šç¯€é»
const nodesInView = await supabase
    .from('nodes')
    .select('*, hub_metadata(*), members(*)')  // âŒ éåº¦æŸ¥è©¢
    .gte('lat', bounds.south)
    .lte('lat', bounds.north)
    .gte('lng', bounds.west)
    .lte('lng', bounds.east);

// çµæœ: zoom=15 æ™‚è¿”å› 5000+ å€‹ nodes
```

**å¯¦éš›æ¸¬é‡**:
- **Zoom 13** (åŸå¸‚ç´š): ~500 nodes, 200KB, 800ms
- **Zoom 15** (å€åŸŸç´š): ~2000 nodes, 800KB, 1500ms
- **Zoom 17** (è¡—é“ç´š): **~5000 nodes, 2MB, 3000ms** âš ï¸

**å•é¡Œåˆ†æ**:
1. **éåº¦æŸ¥è©¢**: `hub_metadata(*)` å’Œ `members(*)` å°è‡´ NÃ—M æŸ¥è©¢
2. **ç„¡åˆ†é **: ä¸€æ¬¡è¿”å›æ‰€æœ‰ç¯€é»
3. **Cache éçŸ­**: 15 ç§’ TTL å°è‡´é »ç¹é‡æ–°æŸ¥è©¢
4. **å»é‡é‚è¼¯**: O(nÂ²) æ¼”ç®—æ³•

**è§£æ±ºæ–¹æ¡ˆ**:

#### çŸ­æœŸä¿®æ­£:
```typescript
// 1. é™åˆ¶è¿”å›æ•¸é‡
.limit(500)  // æœ€å¤š 500 å€‹ç¯€é»

// 2. ç°¡åŒ–æŸ¥è©¢
.select('id, name, type, lat, lng, hub_id')  // åªè¿”å›å¿…è¦æ¬„ä½

// 3. å»¶é•· cache
const CACHE_TTL = 300; // 5 åˆ†é˜ (L1 è³‡æ–™è®Šå‹•æ¥µä½)

// 4. æ”¹ç”¨ Set å»é‡
const uniqueNodes = Array.from(new Set(nodes.map(n => n.id)))
    .map(id => nodes.find(n => n.id === id));
```

#### ä¸­æœŸå„ªåŒ–:
```typescript
// Clustering API: å‰ç«¯æ ¹æ“šç¸®æ”¾å±¤ç´šèšåˆç¯€é»
if (zoom < 14) {
    // è¿”å› Hub ç¯€é» + èšåˆçµ±è¨ˆ
    return {
        hubs: hubNodes,
        clusters: clusterStats  // { center, count, bounds }
    };
} else {
    // è¿”å›å®Œæ•´ç¯€é»
    return { nodes: allNodes };
}
```

### 4. N+1 Coordinate Queries

**ä½ç½®**: `src/app/api/l2/status/route.ts:432`

**å•é¡Œ**:
```typescript
// âŒ ç‚ºæ¯å€‹ station å–®ç¨æŸ¥è©¢åº§æ¨™
for (const station of trainData.stations) {
    const coord = await supabase
        .from('nodes')
        .select('lat, lng')
        .eq('odpt_id', station.id)
        .single();

    station.coordinates = coord;
}
// 10 å€‹è»Šç«™ = 10 æ¬¡æŸ¥è©¢
```

**è§£æ±ºæ–¹æ¡ˆ**:
```typescript
// âœ… æ‰¹æ¬¡æŸ¥è©¢
const stationIds = trainData.stations.map(s => s.id);
const coordinates = await supabase
    .from('nodes')
    .select('odpt_id, lat, lng')
    .in('odpt_id', stationIds);

// å»ºç«‹æŸ¥æ‰¾è¡¨
const coordMap = new Map(coordinates.map(c => [c.odpt_id, c]));

// å–®æ¬¡ O(n) æ˜ å°„
trainData.stations.forEach(s => {
    s.coordinates = coordMap.get(s.id);
});
```

---

## ğŸŸ¢ ä¸­å„ªå…ˆç´šå•é¡Œ (P2 - æ”¹å–„)

### 5. Frontend 8 Chained useEffect Hooks

**ä½ç½®**: `src/app/[locale]/page.tsx:45-120`

**å•é¡Œ**:
```typescript
useEffect(() => { /* 1. Initialize map */ }, []);
useEffect(() => { /* 2. Load user location */ }, [map]);
useEffect(() => { /* 3. Fetch nodes */ }, [bounds]);
useEffect(() => { /* 4. Update markers */ }, [nodes]);
useEffect(() => { /* 5. Fetch status */ }, [selectedNode]);
useEffect(() => { /* 6. Update UI */ }, [status]);
useEffect(() => { /* 7. Subscribe updates */ }, [nodeId]);
useEffect(() => { /* 8. Cleanup */ }, []);
```

**å½±éŸ¿**: å¤šæ¬¡é‡æ–°æ¸²æŸ“,æ•ˆèƒ½æå¤± ~200-400ms

**è§£æ±ºæ–¹æ¡ˆ**:
```typescript
// åˆä½µç›¸é—œ effects
useEffect(() => {
    if (!map || !bounds) return;

    // å–®æ¬¡åŸ·è¡Œ: load nodes + update markers + fetch status
    loadNodesAndStatus(bounds, selectedNode);
}, [map, bounds, selectedNode]);
```

### 6. POI Vector Computation in Memory

**ä½ç½®**: `src/app/api/poi/recommend/route.ts`

**å•é¡Œ**: æ¯æ¬¡è«‹æ±‚éƒ½åœ¨è¨˜æ†¶é«”ä¸­è¨ˆç®—å‘é‡ç›¸ä¼¼åº¦

**è§£æ±ºæ–¹æ¡ˆ**: ç§»è‡³ Supabase RPC å‡½æ•¸ (åˆ©ç”¨ pgvector åŠ é€Ÿ)

---

## ğŸ’° ä¸¦ç™¼èƒ½åŠ›èˆ‡æˆæœ¬ä¼°ç®—

### ç•¶å‰æ¶æ§‹ä¸¦ç™¼èƒ½åŠ›

```
ä¼°ç®—åŸºç¤:
- Serverless ç’°å¢ƒ: 1 instance = 512MB RAM, 0.5 vCPU
- å¹³å‡è«‹æ±‚è™•ç†æ™‚é–“: 2-4 ç§’
- LLM èª¿ç”¨å»¶é²: 3-15 ç§’

ä¸¦ç™¼èƒ½åŠ›è¨ˆç®—:
- å–® instance: 2-5 ä¸¦ç™¼è«‹æ±‚ (è¨˜æ†¶é«”é™åˆ¶)
- 10 instances: 20-50 ä¸¦ç™¼è«‹æ±‚
- CPU ç“¶é ¸: LLM ç­‰å¾…æœŸé–“ä½”ç”¨é€£ç·š

å¯¦æ¸¬ä¼°è¨ˆ: 50-100 ä¸¦ç™¼ç”¨æˆ¶ (å¹³å‡æ¯ç”¨æˆ¶ 1 è«‹æ±‚/30ç§’)
```

### è³‡æºä½¿ç”¨é æ¸¬

| ä¸¦ç™¼ç”¨æˆ¶ | CPU ä½¿ç”¨ç‡ | è¨˜æ†¶é«”å³°å€¼ | LLM Queue | é ä¼°å»¶é² |
|----------|-----------|-----------|-----------|----------|
| 10 | 20-30% | 80 MB | 0 | 2-4s |
| 50 | 60-75% | 180 MB | 0-2 | 3-6s |
| 100 | 80-95% | 235 MB | 5-10 | 8-15s âš ï¸ |
| 200+ | 100% | OOM | 20+ | 30s+ âŒ |

**çµè«–**: **ç•¶å‰æ¶æ§‹æ¥µé™ç´„ 50-100 ä¸¦ç™¼ç”¨æˆ¶**

---

## ğŸ¯ ç”Ÿç”¢ç’°å¢ƒæœå‹™é·ç§»å»ºè­°

### é·ç§»ç­–ç•¥ç¸½è¦½

```
å„ªå…ˆç´šåˆ†å±¤:
P0 (ç«‹å³): LLM Timeout + ODPT è«‹æ±‚å„ªåŒ– (Code-level fixes)
P1 (2é€±å…§): Cache å±¤é·ç§» (Redis/KV)
P2 (1æœˆå…§): LLM è™•ç†åˆ†é›¢ (Dedicated Service)
P3 (3æœˆå…§): Vector Search é·ç§» (Pinecone/Weaviate)
```

### æ–¹æ¡ˆ 1: LLM Processing Service (P2 - é—œéµ)

**å•é¡Œ**: LLM èª¿ç”¨ä½”ç”¨ä¸»æ‡‰ç”¨è³‡æº,é€ æˆé˜»å¡

**é·ç§»ç›®æ¨™**: ç¨ç«‹ LLM è™•ç†æœå‹™

**é¸é … A: Zeabur AI Worker (æ¨è–¦)**
```typescript
// æ¶æ§‹
Client â†’ Next.js API â†’ Zeabur AI Worker (Queue) â†’ LLM Providers
                    â†“
                  Return Job ID
                    â†“
                  Poll/Webhook Result

// å„ªå‹¢
- âœ… èˆ‡ Zeabur æ•´åˆç·Šå¯†
- âœ… è‡ªå‹• Queue + Retry
- âœ… ç¨ç«‹è³‡æºé…é¡
- âœ… æˆæœ¬å¯æ§ (~$10-20/æœˆ)

// å¯¦ä½œ
// 1. å»ºç«‹ AI Worker service
// zeabur.yaml
services:
  - name: lutagu-llm-worker
    type: worker
    env:
      - GEMINI_API_KEY
      - DEEPSEEK_API_KEY
    resources:
      memory: 512MB
      cpu: 0.5

// 2. ä¿®æ”¹ API å‘¼å«
const jobId = await aiWorker.submitJob({
    type: 'llm-synthesis',
    params: { prompt, context }
});

// 3. Webhook æ¥æ”¶çµæœ
// src/app/api/webhooks/ai-worker/route.ts
export async function POST(req: Request) {
    const { jobId, result } = await req.json();
    await updateChatResponse(jobId, result);
    return Response.json({ received: true });
}
```

**é¸é … B: Modal Labs (å½ˆæ€§é«˜)**
- å„ªå‹¢: GPU åŠ é€Ÿ,æŒ‰ç§’è¨ˆè²»
- åŠ£å‹¢: éœ€é¡å¤–æ•´åˆ
- æˆæœ¬: ~$0.05-0.10 per request

**é¸é … C: ä¿æŒç¾ç‹€ + å„ªåŒ–**
- å¯¦ä½œ timeout (P0 å·²æåŠ)
- Streaming response
- æˆæœ¬: $0 (ä½†ä¸¦ç™¼å—é™)

**å»ºè­°**: **ç”Ÿç”¢å‰é·ç§»è‡³ Zeabur AI Worker (é¸é … A)**

---

### æ–¹æ¡ˆ 2: Cache Layer (P1 - é‡è¦)

**å•é¡Œ**: ç•¶å‰ä½¿ç”¨ Supabase è¡¨ä½œç‚º cache,æŸ¥è©¢æ•ˆç‡ä½

**é·ç§»ç›®æ¨™**: Redis / KV Store

**é¸é … A: Upstash Redis (æ¨è–¦)**
```typescript
// å„ªå‹¢
- âœ… Serverless-friendly (æŒ‰è«‹æ±‚è¨ˆè²»)
- âœ… å…¨çƒ Edge locations
- âœ… å…è²»é¡åº¦: 10K requests/day
- âœ… èˆ‡ Vercel æ·±åº¦æ•´åˆ

// å¯¦ä½œ
// 1. å®‰è£ SDK
npm install @upstash/redis

// 2. ä¿®æ”¹ cacheService.ts
import { Redis } from '@upstash/redis';

const redis = new Redis({
    url: process.env.UPSTASH_REDIS_REST_URL,
    token: process.env.UPSTASH_REDIS_REST_TOKEN,
});

export class CacheService {
    static async get<T>(key: string): Promise<T | null> {
        const cached = await redis.get<T>(key);
        return cached;
    }

    static async set<T>(key: string, value: T, ttl: number): Promise<void> {
        await redis.set(key, value, { ex: ttl });
    }
}

// 3. é—œéµ Cache éµ
- `viewport:{bounds}` (5 min TTL)
- `l2-status:{nodeId}` (1 min TTL)
- `odpt:train-info:{lineId}` (30s TTL)
- `poi:nearby:{lat},{lng}` (10 min TTL)
```

**æˆæœ¬ä¼°ç®—**:
- å…è²»é¡åº¦: 10K requests/day â‰ˆ 300K/month
- ä»˜è²»æ–¹æ¡ˆ: $0.20 per 100K requests
- **é ä¼°**: 100 DAU = ~10K cache hits/day = **å…è²»**

**é¸é … B: Vercel KV**
- å„ªå‹¢: åŸç”Ÿæ•´åˆ
- åŠ£å‹¢: æˆæœ¬è¼ƒé«˜ ($20/æœˆèµ·)

**å»ºè­°**: **Upstash Redis (å…è²»é¡åº¦è¶³å¤  MVP)**

---

### æ–¹æ¡ˆ 3: Vector Search (P3 - é•·æœŸ)

**å•é¡Œ**: Supabase pgvector æŸ¥è©¢åœ¨å¤§è¦æ¨¡æ™‚æ•ˆèƒ½ä¸‹é™

**ç•¶å‰ç‹€æ³**:
- `expert_knowledge`: ~500 æ¢è¨˜éŒ„ (1536 ç¶­)
- æŸ¥è©¢æ™‚é–“: 50-150ms (å¯æ¥å—)
- **æœªä¾†è¦æ¨¡**: 10K+ è¨˜éŒ„æ™‚ â†’ 500ms+ âš ï¸

**é·ç§»æ™‚æ©Ÿ**: ç•¶ vector è¡¨è¶…é 5000 æ¢è¨˜éŒ„ OR æŸ¥è©¢æ™‚é–“ > 200ms

**é¸é … A: Pinecone (å°ˆæ¥­)**
```typescript
// å„ªå‹¢
- âœ… å°ˆç‚º vector search å„ªåŒ–
- âœ… è‡ªå‹• scaling
- âœ… æ”¯æ´ metadata filtering
- âœ… 99.9% SLA

// æˆæœ¬
- Free tier: 1 index, 100K vectors
- Paid: $70/æœˆèµ·

// é·ç§»æ­¥é©Ÿ
// 1. Export from Supabase
const { data: vectors } = await supabase
    .from('expert_knowledge')
    .select('id, content, embedding, metadata');

// 2. Upsert to Pinecone
await pinecone.upsert({
    namespace: 'expert-knowledge',
    vectors: vectors.map(v => ({
        id: v.id,
        values: v.embedding,
        metadata: { content: v.content, ...v.metadata }
    }))
});

// 3. ä¿®æ”¹æŸ¥è©¢é‚è¼¯
const results = await pinecone.query({
    vector: queryEmbedding,
    topK: 5,
    includeMetadata: true
});
```

**é¸é … B: Weaviate (é–‹æº)**
- å„ªå‹¢: è‡ªè¨—ç®¡,æˆæœ¬ä½
- åŠ£å‹¢: éœ€ç¶­è­·
- æˆæœ¬: ~$20-40/æœˆ (VM)

**é¸é … C: ä¿æŒ Supabase**
- å„ªåŒ–ç´¢å¼• (HNSW parameters)
- å®šæœŸ VACUUM
- åˆ†å€ (partition by skill_type)

**å»ºè­°**: **çŸ­æœŸä¿æŒ Supabase,DAU > 1000 æ™‚é·ç§»è‡³ Pinecone**

---

### æ–¹æ¡ˆ 4: CDN for Static Assets (P1 - å¿«é€Ÿå‹åˆ©)

**å•é¡Œ**: åœ°åœ– tilesã€åœ–ç‰‡ã€JSON éœæ…‹è³‡æ–™æœªä½¿ç”¨ CDN

**é·ç§»ç›®æ¨™**: Cloudflare CDN / Vercel Edge

**å¯¦ä½œ**:
```typescript
// next.config.js
module.exports = {
    images: {
        domains: ['cdn.lutagu.com'],
        loader: 'custom',
        loaderFile: './src/lib/cloudflare-loader.ts',
    },

    // éœæ…‹è³‡æ–™ CDN
    async rewrites() {
        return [
            {
                source: '/data/:path*',
                destination: 'https://cdn.lutagu.com/data/:path*',
            },
        ];
    },
};

// public/data/ ç›®éŒ„ç§»è‡³ Cloudflare R2
// - station_coordinates.json (1.2 MB)
// - facility_index.json (800 KB)
// - topology_graph.json (2.5 MB)
```

**æ•ˆç›Š**:
- âœ… é™ä½ä¸»ä¼ºæœå™¨é »å¯¬ 80%
- âœ… å…¨çƒå»¶é²é™ä½ 50-200ms
- âœ… æˆæœ¬æ¥µä½ ($0-5/æœˆ)

---

### æ–¹æ¡ˆ 5: Database Query Optimization (P2)

**å•é¡Œ**: éƒ¨åˆ†æŸ¥è©¢æœªä½¿ç”¨ç´¢å¼•

**å„ªåŒ–é …ç›®**:

```sql
-- 1. è¤‡åˆç´¢å¼• (viewport æŸ¥è©¢)
CREATE INDEX idx_nodes_location_type
ON nodes (type, lat, lng)
WHERE type IN ('station', 'hub');

-- 2. éƒ¨åˆ†ç´¢å¼• (å³æ™‚è³‡æ–™)
CREATE INDEX idx_train_info_active
ON train_information (line_id, timestamp DESC)
WHERE status != 'Normal'
AND timestamp > NOW() - INTERVAL '1 hour';

-- 3. JSONB GIN ç´¢å¼• (å¤šèªè¨€æŸ¥è©¢)
CREATE INDEX idx_nodes_name_gin
ON nodes USING gin (name jsonb_path_ops);

-- 4. Vector ç´¢å¼•èª¿å„ª
CREATE INDEX idx_expert_knowledge_vector
ON expert_knowledge
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);  -- æé«˜ lists æ•¸é‡
```

**é æœŸæ•ˆç›Š**: æŸ¥è©¢æ™‚é–“é™ä½ 30-50%

---

## ğŸ“‹ å„ªå…ˆç´šè¡Œå‹•è¨ˆç•«

### Phase 1: ç«‹å³ä¿®æ­£ (P0 - æœ¬é€±å…§)

**å·¥ä½œé‡**: 8-12 å°æ™‚

```
âœ… Task 1: LLM Timeout (2h)
â”œâ”€ ä¿®æ”¹ src/lib/ai/llmClient.ts
â”œâ”€ åŠ å…¥ timeout æ©Ÿåˆ¶ (10-15s)
â”œâ”€ åŠ å…¥ maxTokens é™åˆ¶
â””â”€ æ¸¬è©¦ chat/reasoning/classification å ´æ™¯

âœ… Task 2: ODPT è«‹æ±‚å„ªåŒ– (4h)
â”œâ”€ ç§»é™¤é‡è¤‡ fallback è«‹æ±‚
â”œâ”€ åˆä½µ Promise.all æŸ¥è©¢
â”œâ”€ å¯¦ä½œ Request Deduplication
â””â”€ æ¸¬è©¦é«˜å³°æœŸè¡Œç‚º

âœ… Task 3: N+1 æŸ¥è©¢ä¿®æ­£ (2h)
â”œâ”€ è­˜åˆ¥æ‰€æœ‰ N+1 patterns
â”œâ”€ æ”¹ç”¨æ‰¹æ¬¡æŸ¥è©¢
â””â”€ é©—è­‰æ•ˆèƒ½æ”¹å–„

âœ… Task 4: Viewport Limit (2h)
â”œâ”€ åŠ å…¥ .limit(500)
â”œâ”€ ç°¡åŒ– SELECT æ¬„ä½
â”œâ”€ å»¶é•· cache TTL â†’ 300s
â””â”€ æ¸¬è©¦ä¸åŒç¸®æ”¾å±¤ç´š
```

**é æœŸæ•ˆç›Š**:
- LLM è«‹æ±‚å¤±æ•—ç‡: 30% â†’ 5%
- ODPT Rate Limit éŒ¯èª¤: 80% â†’ 10%
- Viewport å›æ‡‰æ™‚é–“: 3000ms â†’ 800ms
- **æ•´é«”ç©©å®šæ€§æå‡ 60%**

---

### Phase 2: åŸºç¤è¨­æ–½å‡ç´š (P1 - 2é€±å…§)

**å·¥ä½œé‡**: 16-20 å°æ™‚

```
âœ… Task 1: éƒ¨ç½² Upstash Redis (4h)
â”œâ”€ è¨»å†Š Upstash å¸³è™Ÿ
â”œâ”€ å»ºç«‹ Redis instance
â”œâ”€ ä¿®æ”¹ cacheService.ts
â”œâ”€ é·ç§»é—œéµ cache éµ
â””â”€ A/B æ¸¬è©¦æ•ˆèƒ½

âœ… Task 2: CDN è¨­å®š (3h)
â”œâ”€ public/data/ â†’ Cloudflare R2
â”œâ”€ è¨­å®š next.config.js rewrites
â”œâ”€ æ¸¬è©¦éœæ…‹è³‡æºè¼‰å…¥
â””â”€ ç›£æ§é »å¯¬é™ä½

âœ… Task 3: Database ç´¢å¼•å„ªåŒ– (4h)
â”œâ”€ åŸ·è¡Œ EXPLAIN ANALYZE æ‰¾å‡ºæ…¢æŸ¥è©¢
â”œâ”€ å»ºç«‹è¤‡åˆç´¢å¼•
â”œâ”€ èª¿å„ª vector ç´¢å¼•åƒæ•¸
â””â”€ é©—è­‰æŸ¥è©¢è¨ˆç•«æ”¹å–„

âœ… Task 4: Streaming Response (6h)
â”œâ”€ ä¿®æ”¹ chat API ä½¿ç”¨ StreamingTextResponse
â”œâ”€ å‰ç«¯å¯¦ä½œ streaming UI
â”œâ”€ æ¸¬è©¦é•·å›è¦†å ´æ™¯
â””â”€ Fallback è™•ç†

âœ… Task 5: ç›£æ§å„€è¡¨æ¿ (3h)
â”œâ”€ æ•´åˆ Sentry (éŒ¯èª¤è¿½è¹¤)
â”œâ”€ è¨­å®š Grafana (æ•ˆèƒ½ç›£æ§)
â”œâ”€ å»ºç«‹å‘Šè­¦è¦å‰‡
â””â”€ æ¸¬è©¦é€šçŸ¥æ©Ÿåˆ¶
```

**é æœŸæ•ˆç›Š**:
- Cache hit rate: 40% â†’ 85%
- API P95 å»¶é²: 4000ms â†’ 1500ms
- CDN é »å¯¬ç¯€çœ: 80%
- **ç”¨æˆ¶é«”é©—é¡¯è‘—æ”¹å–„**

---

### Phase 3: æœå‹™åˆ†é›¢ (P2 - ç”Ÿç”¢å‰)

**å·¥ä½œé‡**: 24-32 å°æ™‚

```
âœ… Task 1: LLM Worker Service (16h)
â”œâ”€ è¨­å®š Zeabur AI Worker
â”œâ”€ å¯¦ä½œ Job Queue æ©Ÿåˆ¶
â”œâ”€ ä¿®æ”¹ API å‘¼å«æ”¹ç”¨ async job
â”œâ”€ Webhook æ¥æ”¶çµæœ
â”œâ”€ æ¸¬è©¦ failover èˆ‡ retry
â””â”€ æ•ˆèƒ½å°æ¯”æ¸¬è©¦

âœ… Task 2: å‰ç«¯ Code Splitting (8h)
â”œâ”€ Dynamic import for Map components
â”œâ”€ Route-based chunking
â”œâ”€ å»¶é²è¼‰å…¥ Skills UI
â””â”€ Bundle size åˆ†æ

âœ… Task 3: Image Optimization (4h)
â”œâ”€ ä½¿ç”¨ next/image
â”œâ”€ WebP/AVIF æ ¼å¼è½‰æ›
â”œâ”€ Lazy loading
â””â”€ Responsive images

âœ… Task 4: Load Testing (4h)
â”œâ”€ ä½¿ç”¨ k6 æˆ– Artillery
â”œâ”€ æ¨¡æ“¬ 100/500/1000 ä¸¦ç™¼ç”¨æˆ¶
â”œâ”€ è­˜åˆ¥ç“¶é ¸
â””â”€ èª¿æ•´è³‡æºé…ç½®
```

**é æœŸæ•ˆç›Š**:
- ä¸¦ç™¼èƒ½åŠ›: 50-100 â†’ 200-500 ç”¨æˆ¶
- LLM é˜»å¡: æ¶ˆé™¤
- å‰ç«¯è¼‰å…¥æ™‚é–“: 3s â†’ 1.5s

---

### Phase 4: é€²éšå„ªåŒ– (P3 - Post-MVP)

**æ¢ä»¶**: DAU > 1000 æˆ–æ•ˆèƒ½ç›£æ§é¡¯ç¤ºç“¶é ¸

```
âœ… Vector Search é·ç§» (Pinecone)
âœ… Database Read Replicas (Supabase)
âœ… Edge Functions (Cloudflare Workers)
âœ… GraphQL API (å–ä»£ REST)
```

---

## ğŸ’° æˆæœ¬æ•ˆç›Šåˆ†æ

### ç•¶å‰æˆæœ¬ (ä¼°ç®—)

```
Zeabur/Vercel Hosting: $20-40/æœˆ
Supabase: $25/æœˆ (Pro plan)
ODPT API: å…è²»
LLM APIs:
â”œâ”€ Gemini: $0 (å…è²»é¡åº¦)
â”œâ”€ DeepSeek: ~$5-10/æœˆ
â””â”€ MiniMax: ~$5/æœˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç¸½è¨ˆ: ~$55-80/æœˆ
```

### é·ç§»å¾Œæˆæœ¬ (Phase 1-2)

```
Zeabur/Vercel: $20-40/æœˆ
Supabase: $25/æœˆ
Upstash Redis: $0 (å…è²»é¡åº¦)
Cloudflare R2: $0-2/æœˆ
Sentry: $0 (å…è²»é¡åº¦)
LLM APIs: $10-15/æœˆ
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç¸½è¨ˆ: ~$55-82/æœˆ (å¹¾ä¹ä¸è®Š)
```

### é·ç§»å¾Œæˆæœ¬ (Phase 3 - ç”Ÿç”¢)

```
Zeabur Main App: $40/æœˆ
Zeabur AI Worker: $20/æœˆ
Supabase: $25/æœˆ
Upstash Redis: $5/æœˆ (è¶…éå…è²»é¡åº¦)
Cloudflare R2 + CDN: $5/æœˆ
Sentry: $29/æœˆ (Team plan)
LLM APIs: $30-50/æœˆ (æµé‡å¢åŠ )
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç¸½è¨ˆ: ~$154-174/æœˆ
```

### ROI è¨ˆç®—

| æŒ‡æ¨™ | å„ªåŒ–å‰ | å„ªåŒ–å¾Œ | æ”¹å–„å¹…åº¦ |
|------|--------|--------|---------|
| ä¸¦ç™¼èƒ½åŠ› | 50-100 | 200-500 | **4-5x** |
| P95 å»¶é² | 4000ms | 1500ms | **62% â†“** |
| éŒ¯èª¤ç‡ | 15-20% | <5% | **70% â†“** |
| Cache Hit | 40% | 85% | **112% â†‘** |
| æœˆæˆæœ¬ | $70 | $170 | +$100 |
| å–®ç”¨æˆ¶æˆæœ¬ | $0.70 (100 DAU) | $0.17 (1000 DAU) | **76% â†“** |

**çµè«–**: åˆæœŸæˆæœ¬å¢åŠ  $100/æœˆ,ä½†ä¸¦ç™¼èƒ½åŠ›æå‡ 4-5 å€,å–®ç”¨æˆ¶æˆæœ¬åè€Œä¸‹é™ 76%

---

## ğŸ¯ æœ€çµ‚å»ºè­°

### çŸ­æœŸ (æœ¬é€±): âœ… ç«‹å³å¯¦ä½œ P0 ä¿®æ­£

**ä¸éœ€é¡å¤–æˆæœ¬,åƒ…éœ€ code-level ä¿®æ”¹**:

1. âœ… LLM Timeout (2h) â†’ æ¶ˆé™¤ 30-65s å¡æ­»
2. âœ… ODPT è«‹æ±‚åˆä½µ (4h) â†’ é™ä½ Rate Limit éŒ¯èª¤ 80%
3. âœ… Viewport Limit (2h) â†’ å›æ‡‰æ™‚é–“é™ä½ 73%
4. âœ… N+1 æŸ¥è©¢ä¿®æ­£ (2h) â†’ è³‡æ–™åº«è² è¼‰é™ä½ 40%

**é æœŸæ•ˆæœ**: **ã€Œä¸ç©©å®šã€å•é¡Œæ”¹å–„ 60-70%**

---

### ä¸­æœŸ (2é€±å…§): âœ… åŸºç¤è¨­æ–½å‡ç´š

**å¿…è¦æŠ•è³‡**: Upstash Redis (å…è²») + CDN ($0-5/æœˆ)

1. âœ… Redis Cache (4h) â†’ Cache hit æå‡è‡³ 85%
2. âœ… CDN è¨­å®š (3h) â†’ é »å¯¬ç¯€çœ 80%
3. âœ… Streaming Response (6h) â†’ ä½¿ç”¨è€…é«”é©—æ”¹å–„
4. âœ… ç›£æ§ç³»çµ± (3h) â†’ å•é¡Œå¯è¿½è¹¤

**é æœŸæ•ˆæœ**: **ç©©å®šæ€§é”åˆ°ç”Ÿç”¢ç­‰ç´š**

---

### ç”Ÿç”¢å‰ (1æœˆå…§): âœ… æœå‹™åˆ†é›¢

**å»ºè­°æŠ•è³‡**: Zeabur AI Worker ($20/æœˆ) + Sentry ($29/æœˆ)

1. âœ… LLM Worker (16h) â†’ ä¸¦ç™¼èƒ½åŠ› 4x
2. âœ… Code Splitting (8h) â†’ å‰ç«¯è¼‰å…¥å¿« 50%
3. âœ… Load Testing (4h) â†’ é©—è­‰ 500 ä¸¦ç™¼

**é æœŸæ•ˆæœ**: **æ”¯æ´ 200-500 DAU**

---

## ğŸ“ é—œéµæª”æ¡ˆæ¸…å–®

### éœ€ç«‹å³ä¿®æ”¹ (P0):
| æª”æ¡ˆ | å•é¡Œ | é ä¼°æ™‚é–“ |
|------|------|---------|
| `src/lib/ai/llmClient.ts` | ç„¡ timeout | 2h |
| `src/app/api/l2/status/route.ts` | ODPT é‡è¤‡è«‹æ±‚ | 4h |
| `src/app/api/nodes/viewport/route.ts` | éåº¦æŸ¥è©¢ | 2h |

### éœ€ä¸­æœŸæ”¹å–„ (P1):
| æª”æ¡ˆ | æ”¹å–„é …ç›® | é ä¼°æ™‚é–“ |
|------|---------|---------|
| `src/lib/cache/cacheService.ts` | é·ç§»è‡³ Redis | 4h |
| `src/app/api/chat/route.ts` | Streaming Response | 6h |
| `next.config.js` | CDN rewrites | 2h |

### æ–°å»ºæª”æ¡ˆ (P2):
| æª”æ¡ˆ | ç”¨é€” | é ä¼°æ™‚é–“ |
|------|------|---------|
| `services/llm-worker/` | AI Worker Service | 16h |
| `src/lib/monitoring/` | ç›£æ§èˆ‡å‘Šè­¦ | 3h |
| `scripts/load-test.js` | è² è¼‰æ¸¬è©¦ | 4h |

---

## âš ï¸ é¢¨éšªèˆ‡æ³¨æ„äº‹é …

1. **Serverless Cold Start**:
   - å•é¡Œ: é¦–æ¬¡è«‹æ±‚å»¶é² 2-5s
   - ç·©è§£: ä½¿ç”¨ Vercel Edge Functions æˆ–ä¿æŒ warm

2. **LLM API æˆæœ¬**:
   - é¢¨éšª: DeepSeek/Gemini ç”¨é‡è¶…éå…è²»é¡åº¦
   - ç·©è§£: å¯¦ä½œæ¯æ—¥é ç®—é™åˆ¶,è¶…éå‰‡é™ç´šå›æ‡‰

3. **Supabase é€£ç·šæ•¸**:
   - é™åˆ¶: Pro plan 60 connections
   - ç·©è§£: ä½¿ç”¨é€£ç·šæ± ,è¨­å®š max_connections=10

4. **ODPT API ç©©å®šæ€§**:
   - å•é¡Œ: å¶ç™¼æ€§ 503 éŒ¯èª¤
   - ç·©è§£: å¯¦ä½œ exponential backoff retry

5. **å‘é‡æœå°‹æ“´å±•æ€§**:
   - ç•¶å‰: 500 records, 50-150ms
   - è‡¨ç•Œé»: 5000 records, 500ms+
   - è¨ˆç•«: é”åˆ° 3000 records æ™‚è©•ä¼° Pinecone

---

## âœ… é©—è­‰è¨ˆç•«

### æ•ˆèƒ½æ¸¬è©¦æ¸…å–®

```bash
# 1. API å»¶é²æ¸¬è©¦
curl -w "@curl-format.txt" -o /dev/null -s \
  "https://lutagu.com/api/chat" \
  -d '{"message": "ä¸Šé‡ç«™æ€éº¼å»æ·ºè‰?"}'

# é æœŸ: < 2000ms (P0 å¾Œ), < 1000ms (P1 å¾Œ)

# 2. Viewport æŸ¥è©¢æ¸¬è©¦
curl -w "@curl-format.txt" -o /dev/null -s \
  "https://lutagu.com/api/nodes/viewport?bounds=..."

# é æœŸ: < 1000ms (P0 å¾Œ), < 500ms (P1 å¾Œ)

# 3. ODPT Rate Limit æ¸¬è©¦
for i in {1..100}; do
  curl -s "https://lutagu.com/api/l2/status?nodeId=odpt.Station:TokyoMetro.Ginza.Ueno" &
done
wait

# é æœŸ: 0 å€‹ 429 éŒ¯èª¤ (P0 å¾Œ)

# 4. Load Test (éœ€ k6)
k6 run --vus 100 --duration 30s load-test.js

# é æœŸ: P95 < 2000ms, éŒ¯èª¤ç‡ < 5%
```

### ç›£æ§æŒ‡æ¨™

```
é—œéµæŒ‡æ¨™ (Dashboard):
1. API å›æ‡‰æ™‚é–“ (P50/P95/P99)
2. éŒ¯èª¤ç‡ (5xx, Timeout, Rate Limit)
3. LLM èª¿ç”¨æˆåŠŸç‡
4. Cache Hit Rate
5. Database é€£ç·šæ•¸
6. è¨˜æ†¶é«”ä½¿ç”¨ç‡

å‘Šè­¦é–¾å€¼:
- P95 > 3000ms â†’ Slack é€šçŸ¥
- éŒ¯èª¤ç‡ > 10% â†’ PagerDuty
- Cache Hit < 70% â†’ Email
- Memory > 400MB â†’ Warning
```

---

## ğŸ“ ç¸½çµ

### æ ¸å¿ƒç™¼ç¾

1. **ç•¶å‰ç‹€æ…‹**: ç³»çµ±å¯æ”¯æ´ 50-100 ä¸¦ç™¼ç”¨æˆ¶,è¶…éæ­¤è¦æ¨¡æœƒä¸ç©©å®š
2. **ä¸»è¦ç“¶é ¸**: LLM ç„¡ timeout (30-65s) + ODPT é‡è¤‡è«‹æ±‚ + Viewport éåº¦æŸ¥è©¢
3. **å¿«é€Ÿå‹åˆ©**: P0 ä¿®æ­£åƒ…éœ€ 8-12 å°æ™‚,å¯æ”¹å–„ç©©å®šæ€§ 60-70%
4. **ç”Ÿç”¢å°±ç·’**: P1+P2 å„ªåŒ–å¾Œå¯æ”¯æ´ 200-500 DAU,æˆæœ¬å¢åŠ  ~$100/æœˆ

### å„ªå…ˆç´šç¸½çµ

```
ğŸ”´ P0 (æœ¬é€±): Code-level fixes â†’ ç©©å®šæ€§ +60% (æˆæœ¬ $0)
ğŸŸ¡ P1 (2é€±): Redis + CDN â†’ æ•ˆèƒ½ +50% (æˆæœ¬ +$5/æœˆ)
ğŸŸ¢ P2 (1æœˆ): LLM Worker â†’ ä¸¦ç™¼ 4x (æˆæœ¬ +$50/æœˆ)
ğŸ”µ P3 (3æœˆ): Vector Search â†’ æ“´å±•æ€§ (æˆæœ¬ +$70/æœˆ)
```

### ç«‹å³è¡Œå‹•

**å»ºè­°åŸ·è¡Œé †åº**:
1. âœ… æœ¬é€±å¯¦ä½œ P0 ä¿®æ­£ (8-12h)
2. âœ… 2é€±å…§å®Œæˆ P1 åŸºç¤è¨­æ–½ (16-20h)
3. âœ… ç”Ÿç”¢å‰å®Œæˆ P2 æœå‹™åˆ†é›¢ (24-32h)
4. â¸ï¸ P3 æ ¹æ“šå¯¦éš›æµé‡æ±ºå®š

**é æœŸæˆæœ**:
- çŸ­æœŸ: è§£æ±ºã€Œä¸ç©©å®šã€å•é¡Œ
- ä¸­æœŸ: é”åˆ°ç”Ÿç”¢ç­‰ç´šç©©å®šæ€§
- é•·æœŸ: æ”¯æ´ 1000+ DAU æ“´å±•

---

**å ±å‘Šå®Œæˆæ™‚é–“**: 2026-01-13
**ä¸‹æ¬¡å¯©æŸ¥**: P0 å®Œæˆå¾Œ (é è¨ˆ 1 é€±å…§)
