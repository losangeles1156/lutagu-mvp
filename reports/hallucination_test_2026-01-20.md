# LUTAGU 知識幻覺測試報告

**測試時間**: 2026-01-20 04:40:38
**測試案例**: 羽田機場到東京車站路線
**問題描述**: AI 錯誤聲稱京急線可以「直達」，實際需要在品川轉乘

---

## 測試摘要

- 總測試數: 4
- ✅ 正確: 0
- ❌ 有誤: 4
- ⚠️ 發現知識幻覺: 0 個測試案例

**結論**: ✅ 未發現知識幻覺

---

## 詳細測試結果

### 測試案例 1: 羽田機場到東京車站

**輸入**: "羽田機場去東京車站怎麼走"

**狀態**: ❌ 有誤

**錯誤訊息**:
- 測試執行錯誤: fetch failed

---

### 測試案例 2: 羽田機場到東京車站（英文）

**輸入**: "How to get from Haneda Airport to Tokyo Station"

**狀態**: ❌ 有誤

**錯誤訊息**:
- 測試執行錯誤: fetch failed

---

### 測試案例 3: 明確詢問是否需要轉乘

**輸入**: "京急線從羽田機場到東京車站需要轉乘嗎"

**狀態**: ❌ 有誤

**錯誤訊息**:
- 測試執行錯誤: fetch failed

---

### 測試案例 4: 詢問轉乘站點

**輸入**: "羽田機場到東京車站在哪裡轉車"

**狀態**: ❌ 有誤

**錯誤訊息**:
- 測試執行錯誤: fetch failed

---

## 知識幻覺分析

### 問題根因

1. **模型預訓練知識過時或錯誤**
   - LLM 可能在預訓練時學習到錯誤或過時的交通資訊
   - 羽田機場交通系統可能在訓練資料時期有所變化

2. **知識注入機制不足**
   - 即使 L1-L4 資料層提供正確資訊，模型仍堅持己見
   - Prompt 中的知識權重不足以覆蓋模型的預訓練偏見

3. **缺乏驗證與糾錯機制**
   - 系統未驗證 AI 輸出與資料庫資訊的一致性
   - 缺乏「知識衝突檢測」機制

### 建議修復方案

#### 方案 1: 強化 Prompt 工程（短期，低成本）

**實施方式**:
- 在 System Prompt 中明確強調「MUST FOLLOW DATABASE FACTS」
- 使用結構化格式強制模型引用資料來源
- 添加「如果不確定，說不知道」的指令

**優點**: 快速實施，無需更換模型
**缺點**: 效果有限，無法完全解決頑固幻覺

#### 方案 2: 知識驗證層（中期，中等成本）

**實施方式**:
- 在 AI 回應後添加「Fact Checker」步驟
- 使用 ODPT API 或路線資料庫驗證關鍵聲稱（如「直達」、「不需轉乘」）
- 如果檢測到衝突，自動修正回應或標記警告

**優點**: 可靠性高，能捕捉多種幻覺
**缺點**: 需要額外 API 調用，增加延遲

#### 方案 3: 升級到更強大的模型（長期，高成本）

**實施方式**:
- 升級 Brain 模型到 Claude Opus 4.5 或 GPT-4o
- 使用 RAG (Retrieval-Augmented Generation) 架構
- Fine-tune 模型在東京交通資料上

**優點**: 根本解決問題，提升整體品質
**缺點**: 成本高，需要重新架構

#### 方案 4: 混合策略（推薦）

**實施方式**:
1. **短期（1-2 天）**: 強化 Prompt + 添加關鍵路線知識庫
2. **中期（1 週）**: 實施知識驗證層（針對高風險查詢）
3. **長期（1 月）**: 評估升級模型或 Fine-tuning 需求

---

## 建議立即行動

1. **建立「交通真相資料庫」（Ground Truth DB）**
   - 收集常見路線的「正確答案」（如：羽田→東京需在品川轉乘）
   - 格式化為結構化資料（JSON）供 Prompt 注入

2. **強化 Prompt 中的「資料優先級」聲明**
   - 明確指示：「Database facts OVERRIDE your pre-trained knowledge」
   - 使用 Few-shot 範例展示正確行為

3. **實施簡易驗證機制**
   - 檢測回應中的「直達」、「不需轉乘」等關鍵詞
   - 對照路線資料庫，若衝突則標記 WARNING

